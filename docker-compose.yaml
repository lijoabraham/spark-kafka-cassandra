version: '3'
networks:
    datapipeline:
        driver: bridge
        ipam:
            driver: default
            config:
                - subnet: "172.18.0.0/16"

services:  
  spark_master:
    image: docker.io/bitnami/spark:3.2.1
    hostname: spark
    user: root
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - ./data:/home
      - ./app/:/usr/local/spark/app
    networks:
      datapipeline:
        ipv4_address: 172.18.0.2
  zookeeper:
    image: 'wurstmeister/zookeeper'
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      datapipeline:
        ipv4_address: 172.18.0.3
  kafka:
    image: 'wurstmeister/kafka'
    container_name: kafka
    hostname: kafka
    ports:
     - "9092:9092"
    expose:
     - "9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://kafka:9093,OUTSIDE://kafka:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "lijo-test-topic:1:1"
      KAFKA_ADVERTISED_HOST_NAME: kafka
    depends_on:
      - zookeeper
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data:/home
    networks:
      datapipeline:
        ipv4_address: 172.18.0.4
  cassandra:
    image: 'bitnami/cassandra:latest'
    container_name: cassandra
    hostname: cassandra
    ports:
      - '9042:9042'
    volumes:
      - ./data:/home
    environment:
      - CASSANDRA_HOST=cassandra
    networks:
      datapipeline:
        ipv4_address: 172.18.0.5
  presto:
    image: ahanaio/prestodb-sandbox
    ports:
      - "8080:8080"
    networks:
      datapipeline:
        ipv4_address: 172.18.0.6
  python-worker:
    build: .
    image: python-docker
    environment:
          - SPARK_MODE=worker
          - SPARK_MASTER_URL=spark://spark:7077
          - SPARK_WORKER_MEMORY=1G
          - SPARK_WORKER_CORES=1
          - SPARK_LOCAL_IP=127.0.0.1
          - SPARK_MASTER_HOST= 0.0.0.0
          - SPARK_RPC_AUTHENTICATION_ENABLED=no
          - SPARK_RPC_ENCRYPTION_ENABLED=no
          - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
          - SPARK_SSL_ENABLED=no
    volumes:
      - .:/home/app
    stdin_open: true
    tty: true
    networks:
      datapipeline:
        ipv4_address: 172.18.0.7
  superset:
        image: amancevice/superset:latest
        restart: always
        environment:
            MYSQL_USER: 'superset'
            MYSQL_PASS: 'superset'
            MYSQL_DATABASE: 'superset'
            MYSQL_HOST: 'mysql'
            MYSQL_PORT: 3307
            REDIS_HOST: 'redis'
            REDIS_PORT: 6379
        ports:
            - 8088:8088
            - 5555:5555
        depends_on:
            - mysql
            - redis
        volumes:
            - ./src/app/configs/superset_config.py:/etc/superset/superset_config.py
        networks:
          datapipeline:
            ipv4_address: 172.18.0.8
  redis:
      image: redis:3.2
      restart: always
      ports:
          - 6379:6379
      volumes:
          - ./redis:/data
      networks:
          datapipeline:
            ipv4_address: 172.18.0.9
  mysql:
      image: mysql:5.7
      restart: always
      environment:
          MYSQL_USER: 'superset'
          MYSQL_PASSWORD: 'superset'
          MYSQL_DATABASE: 'superset'
          MYSQL_ROOT_PASSWORD: 'root'
      ports:
          - 3307:3307
      volumes:
          - ./mysql:/var/lib/mysql
      networks:
          datapipeline:
            ipv4_address: 172.18.0.10